date
Sun 20 Nov 2022 08:51:50 PM CST

# node info: 192.168.2.66

# registry details
reg_name='192.168.2.100'
reg_port='5000'

# create a cluster with the local registry enabled in containerd
cat <<EOF | kind create cluster --name=cluster2 --image=192.168.2.100:5000/kindest/node:v1.23.4 --config=-
kind: Cluster
apiVersion: kind.x-k8s.io/v1alpha4
networking:
        disableDefaultCNI: true
        podSubnet: "10.20.0.0/16"
        serviceSubnet: "10.21.0.0/16"

nodes:
        - role: control-plane
        - role: worker


containerdConfigPatches:
- |-
  [plugins."io.containerd.grpc.v1.cri".registry.mirrors."${reg_name}:${reg_port}"]
    endpoint = ["http://${reg_name}:5000"]
EOF
Creating cluster "cluster2" ...
 • Ensuring node image (192.168.2.100:5000/kindest/node:v1.23.4) 🖼  ...
 ✓ Ensuring node image (192.168.2.100:5000/kindest/node:v1.23.4) 🖼
 • Preparing nodes 📦 📦   ...
 ✓ Preparing nodes 📦 📦 
 • Writing configuration 📜  ...
 ✓ Writing configuration 📜
 • Starting control-plane 🕹️  ...
 ✓ Starting control-plane 🕹️
 • Installing StorageClass 💾  ...
 ✓ Installing StorageClass 💾
 • Joining worker nodes 🚜  ...
 ✓ Joining worker nodes 🚜
Set kubectl context to "kind-cluster2"
You can now use your cluster with:

kubectl cluster-info --context kind-cluster2

Have a nice day! 👋

# prep the environment
controller_node=$(kubectl get nodes --no-headers  -o custom-columns=NAME:.metadata.name| grep control-plane)
kubectl taint nodes $controller_node node-role.kubernetes.io/master:NoSchedule-
node/cluster2-control-plane untainted
kubectl get nodes -owide 
NAME                     STATUS     ROLES                  AGE   VERSION   INTERNAL-IP   EXTERNAL-IP   OS-IMAGE       KERNEL-VERSION      CONTAINER-RUNTIME
cluster2-control-plane   NotReady   control-plane,master   48s   v1.23.4   172.18.0.5    <none>        Ubuntu 21.10   5.15.0-52-generic   containerd://1.5.10
cluster2-worker          NotReady   <none>                 12s   v1.23.4   172.18.0.6    <none>        Ubuntu 21.10   5.15.0-52-generic   containerd://1.5.10
kubectl get pods -owide -A
NAMESPACE            NAME                                             READY   STATUS    RESTARTS   AGE   IP           NODE                     NOMINATED NODE   READINESS GATES
kube-system          coredns-64897985d-crscx                          0/1     Pending   0          30s   <none>       <none>                   <none>           <none>
kube-system          coredns-64897985d-jcvcp                          0/1     Pending   0          30s   <none>       <none>                   <none>           <none>
kube-system          etcd-cluster2-control-plane                      1/1     Running   0          46s   172.18.0.5   cluster2-control-plane   <none>           <none>
kube-system          kube-apiserver-cluster2-control-plane            1/1     Running   0          47s   172.18.0.5   cluster2-control-plane   <none>           <none>
kube-system          kube-controller-manager-cluster2-control-plane   1/1     Running   0          47s   172.18.0.5   cluster2-control-plane   <none>           <none>
kube-system          kube-proxy-nzvxb                                 1/1     Running   0          11s   172.18.0.6   cluster2-worker          <none>           <none>
kube-system          kube-proxy-xgh5s                                 1/1     Running   0          30s   172.18.0.5   cluster2-control-plane   <none>           <none>
kube-system          kube-scheduler-cluster2-control-plane            1/1     Running   0          46s   172.18.0.5   cluster2-control-plane   <none>           <none>
local-path-storage   local-path-provisioner-5ddd94ff66-nlw5p          0/1     Pending   0          30s   <none>       <none>                   <none>           <none>

# install CNI
#helm template cilium cilium/cilium --set k8sServiceHost=$controller_node --set k8sServicePort=6443 --version 1.12.0 --namespace kube-system --set ipam.mode=kubernetes --set cluster.id=2 --set cluster.name=cluster2 > ./cluster2-cilium_vxlan.yaml
#kubectl apply -f ./cluster2-cilium_vxlan.yaml

cilium install --context kind-cluster2 --version v1.12.0 --helm-set ipam.mode=kubernetes,cluster.name=cluster2,cluster.id=2 --inherit-ca kind-cluster1
🔮 Auto-detected Kubernetes kind: kind
✨ Running "kind" validation checks
✅ Detected kind version "0.17.0"
ℹ️  Using Cilium version 1.12.0
🔮 Auto-detected cluster name: kind-cluster2
🔮 Auto-detected datapath mode: tunnel
ℹ️  helm template --namespace kube-system cilium cilium/cilium --version 1.12.0 --set cluster.id=2,cluster.name=cluster2,encryption.nodeEncryption=false,ipam.mode=kubernetes,kubeProxyReplacement=disabled,operator.replicas=1,serviceAccounts.cilium.name=cilium,serviceAccounts.operator.name=cilium-operator,tunnel=vxlan
ℹ️  Storing helm values file in kube-system/cilium-cli-helm-values Secret
🔑 Found CA in secret cilium-ca
🔑 Generating certificates for Hubble...
🚀 Creating Service accounts...
🚀 Creating Cluster roles...
🚀 Creating ConfigMap for Cilium version 1.12.0...
🚀 Creating Agent DaemonSet...
🚀 Creating Operator Deployment...
⌛ Waiting for Cilium to be installed and ready...
♻️  Restarting unmanaged pods...
♻️  Restarted unmanaged pod kube-system/coredns-64897985d-crscx
♻️  Restarted unmanaged pod kube-system/coredns-64897985d-jcvcp
♻️  Restarted unmanaged pod local-path-storage/local-path-provisioner-5ddd94ff66-nlw5p
✅ Cilium was successfully installed! Run 'cilium status' to view installation health
cilium status  --context kind-cluster2 --wait
[33m    /¯¯\
[36m /¯¯[33m\__/[32m¯¯\[0m    Cilium:         [32mOK[0m
[36m \__[31m/¯¯\[32m__/[0m    Operator:       [32mOK[0m
[32m /¯¯[31m\__/[35m¯¯\[0m    Hubble:         [36mdisabled[0m
[32m \__[34m/¯¯\[35m__/[0m    ClusterMesh:    [36mdisabled[0m
[34m    \__/
[0m
Deployment        cilium-operator    Desired: 1, Ready: [32m1/1[0m, Available: [32m1/1[0m
DaemonSet         cilium             Desired: 2, Ready: [32m2/2[0m, Available: [32m2/2[0m
Containers:       cilium-operator    Running: [32m1[0m
                  cilium             Running: [32m2[0m
Cluster Pods:     0/6 managed by Cilium
Image versions    cilium             quay.io/cilium/cilium:v1.12.0@sha256:079baa4fa1b9fe638f96084f4e0297c84dd4fb215d29d2321dcbe54273f63ade: 2
                  cilium-operator    quay.io/cilium/operator-generic:v1.12.0@sha256:bb2a42eda766e5d4a87ee8a5433f089db81b72dd04acf6b59fcbb445a95f9410: 1

# prep the necessary tools
for i in $(docker ps  -a --format "table {{.Names}}"|grep cluster2 );
do 
echo $i;
docker cp /usr/bin/ping $i:/usr/bin/ping;
docker cp /usr/bin/cilium $i:/usr/bin/cilium
docker exec -it $i  bash -c "sed -i -e 's/jp.archive.ubuntu.com\|archive.ubuntu.com\|security.ubuntu.com/old-releases.ubuntu.com/g' /etc/apt/sources.list";docker exec -it $i bash -c "apt-get -y update >/dev/null && apt-get -y install net-tools tcpdump >/dev/null"
done
cluster2-control-plane
debconf: delaying package configuration, since apt-utils is not installed
cluster2-worker
debconf: delaying package configuration, since apt-utils is not installed
