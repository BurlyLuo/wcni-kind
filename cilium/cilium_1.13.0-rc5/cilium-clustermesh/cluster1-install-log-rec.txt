date
Sun 20 Nov 2022 08:51:36 PM CST

# node info: 192.168.2.66

# registry details
reg_name='192.168.2.100'
reg_port='5000'

# create a cluster with the local registry enabled in containerd
cat <<EOF | kind create cluster --name=cluster1 --image=192.168.2.100:5000/kindest/node:v1.23.4 --config=-
kind: Cluster
apiVersion: kind.x-k8s.io/v1alpha4
networking:
        disableDefaultCNI: true
        podSubnet: "10.10.0.0/16"
        serviceSubnet: "10.11.0.0/16"

nodes:
        - role: control-plane
        - role: worker


containerdConfigPatches:
- |-
  [plugins."io.containerd.grpc.v1.cri".registry.mirrors."${reg_name}:${reg_port}"]
    endpoint = ["http://${reg_name}:5000"]
EOF
Creating cluster "cluster1" ...
 • Ensuring node image (192.168.2.100:5000/kindest/node:v1.23.4) 🖼  ...
 ✓ Ensuring node image (192.168.2.100:5000/kindest/node:v1.23.4) 🖼
 • Preparing nodes 📦 📦   ...
 ✓ Preparing nodes 📦 📦 
 • Writing configuration 📜  ...
 ✓ Writing configuration 📜
 • Starting control-plane 🕹️  ...
 ✓ Starting control-plane 🕹️
 • Installing StorageClass 💾  ...
 ✓ Installing StorageClass 💾
 • Joining worker nodes 🚜  ...
 ✓ Joining worker nodes 🚜
Set kubectl context to "kind-cluster1"
You can now use your cluster with:

kubectl cluster-info --context kind-cluster1

Have a nice day! 👋

# prep the environment
controller_node=$(kubectl get nodes --no-headers  -o custom-columns=NAME:.metadata.name| grep control-plane)
kubectl taint nodes $controller_node node-role.kubernetes.io/master:NoSchedule-
node/cluster1-control-plane untainted
kubectl get nodes -owide 
NAME                     STATUS     ROLES                  AGE   VERSION   INTERNAL-IP   EXTERNAL-IP   OS-IMAGE       KERNEL-VERSION      CONTAINER-RUNTIME
cluster1-control-plane   NotReady   control-plane,master   37s   v1.23.4   172.18.0.3    <none>        Ubuntu 21.10   5.15.0-52-generic   containerd://1.5.10
cluster1-worker          NotReady   <none>                 0s    v1.23.4   172.18.0.4    <none>        Ubuntu 21.10   5.15.0-52-generic   containerd://1.5.10
kubectl get pods -owide -A
NAMESPACE            NAME                                             READY   STATUS    RESTARTS   AGE   IP           NODE                     NOMINATED NODE   READINESS GATES
kube-system          coredns-64897985d-fg6v5                          0/1     Pending   0          15s   <none>       <none>                   <none>           <none>
kube-system          coredns-64897985d-nblr4                          0/1     Pending   0          15s   <none>       <none>                   <none>           <none>
kube-system          etcd-cluster1-control-plane                      1/1     Running   0          29s   172.18.0.3   cluster1-control-plane   <none>           <none>
kube-system          kube-apiserver-cluster1-control-plane            1/1     Running   0          29s   172.18.0.3   cluster1-control-plane   <none>           <none>
kube-system          kube-controller-manager-cluster1-control-plane   1/1     Running   0          27s   172.18.0.3   cluster1-control-plane   <none>           <none>
kube-system          kube-proxy-b6kz5                                 0/1     Pending   0          0s    <none>       cluster1-worker          <none>           <none>
kube-system          kube-proxy-lkhrh                                 1/1     Running   0          16s   172.18.0.3   cluster1-control-plane   <none>           <none>
kube-system          kube-scheduler-cluster1-control-plane            1/1     Running   0          31s   172.18.0.3   cluster1-control-plane   <none>           <none>
local-path-storage   local-path-provisioner-5ddd94ff66-xtsmk          0/1     Pending   0          15s   <none>       <none>                   <none>           <none>

# install CNI
#helm template cilium cilium/cilium --set k8sServiceHost=$controller_node --set k8sServicePort=6443 --version 1.12.0 --namespace kube-system --set ipam.mode=kubernetes --set cluster.id=1 --set cluster.name=cluster1>./cluster1-cilium_vxlan.yaml
#kubectl apply -f ./cluster1-cilium_vxlan.yaml
cilium install --context kind-cluster1 --version v1.12.0 --helm-set ipam.mode=kubernetes,cluster.name=cluster1,cluster.id=1
🔮 Auto-detected Kubernetes kind: kind
✨ Running "kind" validation checks
✅ Detected kind version "0.17.0"
ℹ️  Using Cilium version 1.12.0
🔮 Auto-detected cluster name: kind-cluster1
🔮 Auto-detected datapath mode: tunnel
ℹ️  helm template --namespace kube-system cilium cilium/cilium --version 1.12.0 --set cluster.id=1,cluster.name=cluster1,encryption.nodeEncryption=false,ipam.mode=kubernetes,kubeProxyReplacement=disabled,operator.replicas=1,serviceAccounts.cilium.name=cilium,serviceAccounts.operator.name=cilium-operator,tunnel=vxlan
ℹ️  Storing helm values file in kube-system/cilium-cli-helm-values Secret
🔑 Created CA in secret cilium-ca
🔑 Generating certificates for Hubble...
🚀 Creating Service accounts...
🚀 Creating Cluster roles...
🚀 Creating ConfigMap for Cilium version 1.12.0...
🚀 Creating Agent DaemonSet...
🚀 Creating Operator Deployment...
⌛ Waiting for Cilium to be installed and ready...
✅ Cilium was successfully installed! Run 'cilium status' to view installation health
cilium status  --context kind-cluster1 --wait
[33m    /¯¯\
[36m /¯¯[33m\__/[32m¯¯\[0m    Cilium:         [32mOK[0m
[36m \__[31m/¯¯\[32m__/[0m    Operator:       [32mOK[0m
[32m /¯¯[31m\__/[35m¯¯\[0m    Hubble:         [36mdisabled[0m
[32m \__[34m/¯¯\[35m__/[0m    ClusterMesh:    [36mdisabled[0m
[34m    \__/
[0m
Deployment        cilium-operator    Desired: 1, Ready: [32m1/1[0m, Available: [32m1/1[0m
DaemonSet         cilium             Desired: 2, Ready: [32m2/2[0m, Available: [32m2/2[0m
Containers:       cilium             Running: [32m2[0m
                  cilium-operator    Running: [32m1[0m
Cluster Pods:     3/3 managed by Cilium
Image versions    cilium             quay.io/cilium/cilium:v1.12.0@sha256:079baa4fa1b9fe638f96084f4e0297c84dd4fb215d29d2321dcbe54273f63ade: 2
                  cilium-operator    quay.io/cilium/operator-generic:v1.12.0@sha256:bb2a42eda766e5d4a87ee8a5433f089db81b72dd04acf6b59fcbb445a95f9410: 1

# prep the necessary tools
for i in $(docker ps  -a --format "table {{.Names}}"|grep cluster1 );
do 
echo $i;
docker cp /usr/bin/ping $i:/usr/bin/ping;
docker cp /usr/bin/cilium $i:/usr/bin/cilium;
docker exec -it $i  bash -c "sed -i -e 's/jp.archive.ubuntu.com\|archive.ubuntu.com\|security.ubuntu.com/old-releases.ubuntu.com/g' /etc/apt/sources.list";docker exec -it $i bash -c "apt-get -y update >/dev/null && apt-get -y install net-tools tcpdump >/dev/null"
done
cluster1-worker
debconf: delaying package configuration, since apt-utils is not installed
cluster1-control-plane
debconf: delaying package configuration, since apt-utils is not installed
